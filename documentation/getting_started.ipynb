{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono-S2S: Getting Started\n",
    "\n",
    "This notebook explains how to run and extend the monotonic sequence-to-sequence experiments on HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n",
    "**Goal:** Compare adversarial robustness of monotonic vs. standard T5 models on summarization.\n",
    "\n",
    "**Key idea:** Enforce non-negative weights ($W \\geq 0$) in FFN layers via softplus reparameterization.\n",
    "\n",
    "**Pipeline stages:**\n",
    "| Stage | Script | Purpose |\n",
    "|-------|--------|----------|\n",
    "| 0 | `stage_0_setup.py` | Environment setup |\n",
    "| 1 | `stage_1_prepare_data.py` | Download & preprocess datasets |\n",
    "| 2 | `stage_2_train_baseline.py` | Train unconstrained T5 |\n",
    "| 3 | `stage_3_train_monotonic.py` | Train monotonic T5 (W≥0) |\n",
    "| 4 | `stage_4_evaluate.py` | ROUGE evaluation |\n",
    "| 5 | `stage_5_uat_attacks.py` | Universal adversarial triggers |\n",
    "| 6 | `stage_6_hotflip_attacks.py` | Gradient-based attacks |\n",
    "| 7 | `stage_7_aggregate.py` | Compile final results |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory Structure\n",
    "\n",
    "```\n",
    "mono-s2s/\n",
    "├── hpc_version/\n",
    "│   ├── configs/\n",
    "│   │   └── experiment_config.py    # All hyperparameters here\n",
    "│   ├── scripts/\n",
    "│   │   └── stage_*.py              # Pipeline stages\n",
    "│   ├── jobs/\n",
    "│   │   └── job_*.sh                # SLURM job scripts\n",
    "│   ├── utils/\n",
    "│   │   └── common_utils.py         # Shared utilities\n",
    "│   ├── run_all.sh                  # Master orchestrator\n",
    "│   ├── clean_all.sh                # Reset everything\n",
    "│   └── clean_checkpoints.sh        # Reset models only\n",
    "└── documentation/\n",
    "    └── this notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Running an Experiment\n",
    "\n",
    "### On Alpine HPC:\n",
    "\n",
    "```bash\n",
    "# Clone and navigate\n",
    "git clone <repo_url>\n",
    "cd mono-s2s/hpc_version\n",
    "\n",
    "# Run full pipeline (submits SLURM jobs with dependencies)\n",
    "./run_all.sh 42  # 42 is the random seed\n",
    "\n",
    "# Monitor progress\n",
    "squeue -u $USER\n",
    "```\n",
    "\n",
    "### Restarting:\n",
    "\n",
    "```bash\n",
    "# Clean everything and start fresh\n",
    "./clean_all.sh\n",
    "./run_all.sh 42\n",
    "\n",
    "# Or just retrain models (keep datasets)\n",
    "./clean_checkpoints.sh\n",
    "./run_all.sh 42\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration\n",
    "\n",
    "All hyperparameters are in `configs/experiment_config.py`. Key settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key configuration options (from experiment_config.py)\n",
    "\n",
    "# Model\n",
    "MODEL_NAME = \"t5-small\"  # Options: t5-small, t5-base, t5-large\n",
    "\n",
    "# Training\n",
    "LEARNING_RATE = 5e-5\n",
    "NUM_EPOCHS = 5           # Baseline epochs\n",
    "MONOTONIC_NUM_EPOCHS = 7 # Monotonic gets more epochs\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Evaluation\n",
    "USE_FULL_TEST_SETS = False  # True for paper, False for quick tests\n",
    "QUICK_TEST_SIZE = 200       # Samples when USE_FULL_TEST_SETS=False\n",
    "\n",
    "# Attacks\n",
    "ATTACK_TRIGGER_LENGTH = 5\n",
    "ATTACK_NUM_ITERATIONS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Adding a New Experiment\n",
    "\n",
    "### Option A: Change hyperparameters\n",
    "\n",
    "1. Edit `configs/experiment_config.py`\n",
    "2. Run `./clean_checkpoints.sh` (keeps datasets)\n",
    "3. Run `./run_all.sh <new_seed>`\n",
    "\n",
    "### Option B: Add a new attack type\n",
    "\n",
    "1. Create `scripts/stage_X_new_attack.py` following existing patterns\n",
    "2. Create `jobs/job_X_new_attack.sh` (copy from job_5 or job_6)\n",
    "3. Add to `run_all.sh` with appropriate dependencies\n",
    "\n",
    "### Option C: Add a new model variant\n",
    "\n",
    "1. Add constraint logic in `utils/common_utils.py` (see `make_model_monotonic()`)\n",
    "2. Create new training script (copy from stage_3)\n",
    "3. Update evaluation to include new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Understanding the Monotonic Constraint\n",
    "\n",
    "The key modification is in `utils/common_utils.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softplus parametrization ensures W >= 0\n",
    "class SoftplusParametrization(nn.Module):\n",
    "    def forward(self, V):\n",
    "        return F.softplus(V)  # W = log(1 + exp(V)) >= 0\n",
    "\n",
    "# Applied to FFN layers: wi, wi_0, wi_1, wo\n",
    "# Attention, LayerNorm, residuals are UNCONSTRAINED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Output Files\n",
    "\n",
    "Results are saved to `$SCRATCH/mono_s2s_results/`:\n",
    "\n",
    "| File | Contents |\n",
    "|------|----------|\n",
    "| `evaluation_results.json` | ROUGE scores with confidence intervals |\n",
    "| `uat_results.json` | Universal trigger attack results |\n",
    "| `hotflip_results.json` | Gradient attack results |\n",
    "| `final_results.json` | Aggregated summary |\n",
    "| `experiment_summary.txt` | Human-readable report |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| Job stuck in queue | Normal, can take 24h+ on busy clusters |\n",
    "| \"Flag not created\" error | Script auto-fixes if checkpoints exist |\n",
    "| Out of memory | Reduce `BATCH_SIZE` in config |\n",
    "| Want to resume | Just re-run `./run_all.sh`, it skips completed stages |\n",
    "\n",
    "Check job logs:\n",
    "```bash\n",
    "tail -f logs/job_3_monotonic_*.out  # Live output\n",
    "cat logs/job_3_monotonic_*.err      # Errors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Reference\n",
    "\n",
    "```bash\n",
    "# Run experiment\n",
    "./run_all.sh 42\n",
    "\n",
    "# Check status\n",
    "squeue -u $USER\n",
    "\n",
    "# Clean and restart\n",
    "./clean_all.sh && ./run_all.sh 42\n",
    "\n",
    "# Retrain models only\n",
    "./clean_checkpoints.sh && ./run_all.sh 42\n",
    "\n",
    "# View results\n",
    "cat $SCRATCH/mono_s2s_results/experiment_summary.txt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
